{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2xm_hI-jhliX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v0\")\n",
        "n_observations = env.observation_space.n\n",
        "n_actions = env.action_space.n"
      ],
      "metadata": {
        "id": "hCpnh0AphmIM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the Q-table to 0\n",
        "Q_table = np.zeros((n_observations,n_actions))\n",
        "print(Q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlaY289ohmKg",
        "outputId": "91acdaba-73bf-4f9a-8614-3faa7a53680d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#number of episode we will run\n",
        "n_episodes = 10000\n",
        "\n",
        "#maximum of iteration per episode\n",
        "max_iter_episode = 100\n",
        "\n",
        "#initialize the exploration probability to 1\n",
        "exploration_proba = 1\n",
        "\n",
        "#exploartion decreasing decay for exponential decreasing\n",
        "exploration_decreasing_decay = 0.001\n",
        "\n",
        "# minimum of exploration proba\n",
        "min_exploration_proba = 0.01\n",
        "\n",
        "#discounted factor\n",
        "gamma = 0.99\n",
        "\n",
        "#learning rate\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "-l3IOcXbhmM5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_rewards_episode = list()\n",
        "rewards_per_episode=[]"
      ],
      "metadata": {
        "id": "Jpu8AaCPhmPb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we iterate over episodes\n",
        "for e in range(n_episodes):\n",
        "    #we initialize the first state of the episode\n",
        "    current_state = env.reset()\n",
        "    done = False\n",
        "    \n",
        "    #sum the rewards that the agent gets from the environment\n",
        "    total_episode_reward = 0\n",
        "    \n",
        "    \n",
        "    for i in range(max_iter_episode): \n",
        "        # we sample a float from a uniform distribution over 0 and 1\n",
        "        # if the sampled flaot is less than the exploration proba\n",
        "        #     the agent selects arandom action\n",
        "        # else\n",
        "        #     he exploits his knowledge using the bellman equation \n",
        "        \n",
        "        if np.random.uniform(0,1) < exploration_proba:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q_table[current_state,:])\n",
        "        \n",
        "        # The environment runs the chosen action and returns\n",
        "        # the next state, a reward and true if the epiosed is ended.\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        \n",
        "        # We update our Q-table using the Q-learning iteration\n",
        "        Q_table[current_state, action] = (1-lr) * Q_table[current_state, action] +lr*(reward + gamma*max(Q_table[next_state,:]))\n",
        "        total_episode_reward = total_episode_reward + reward\n",
        "        # If the episode is finished, we leave the for loop\n",
        "        if done:\n",
        "            break\n",
        "        current_state = next_state\n",
        "    #We update the exploration proba using exponential decay formula \n",
        "    exploration_proba = max(min_exploration_proba, np.exp(-exploration_decreasing_decay*e))\n",
        "    rewards_per_episode.append(total_episode_reward)"
      ],
      "metadata": {
        "id": "xCtDd5PMhmR9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean reward per thousand episodes\")\n",
        "for i in range(10):\n",
        "    print((i+1)*1000 , \": mean espiode reward: \",\n",
        "           np.mean(rewards_per_episode[1000*i:1000*(i+1)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eto_UqsAhmUW",
        "outputId": "2ac18fed-6ca8-4e58-df06-d7f200a6fae2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward per thousand episodes\n",
            "1000 : mean espiode reward:  0.038\n",
            "2000 : mean espiode reward:  0.218\n",
            "3000 : mean espiode reward:  0.421\n",
            "4000 : mean espiode reward:  0.592\n",
            "5000 : mean espiode reward:  0.645\n",
            "6000 : mean espiode reward:  0.711\n",
            "7000 : mean espiode reward:  0.707\n",
            "8000 : mean espiode reward:  0.678\n",
            "9000 : mean espiode reward:  0.654\n",
            "10000 : mean espiode reward:  0.665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DoNcsaPChmZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qxMIMaM7hmb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "umQ51wjVhmec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_arTfP9thmg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qeE84-E6hmjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x3dis6unhml4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9uqwF6BkhmoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3xvWe7k5hmqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I_FyNGTGhmtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EE0-jIiuhmv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y4kraGyUhmyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QVzuniDLhm1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xhTDJLg7hm3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6lrsmEYdhm6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vgKZjwXehm8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5T2ADjfjhm_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cgOlWzauhnCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KOMk2zaghnER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jXjFJRKShnKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e2rN9c1PhnNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kmtHMblxhnQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KykGcPpjhnSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c_hmtdl1hnVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kBAwW0JIhnXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MAAzqsNchnaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qLt5Mup4hndH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xkXlAA-5hnfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RD817thVhniS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m7inr88Hhnqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JUrnR14Shnwm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}